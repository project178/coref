{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMXF8EQD4JY3"
      },
      "source": [
        "# Projet pour le cours Sémantique computationnelle\n",
        "### Fait par Mariya Borovikova"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixf5FQmzoMxw"
      },
      "source": [
        "%%capture\n",
        "!pip install sklearn-crfsuite\n",
        "!pip3 install fasttext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XWkpBdMp3XJ"
      },
      "source": [
        "!git clone https://github.com/project178/coref"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84HzQSvln9Jn"
      },
      "source": [
        "import copy\n",
        "import fasttext\n",
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import sklearn_crfsuite\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from tqdm.auto import tqdm\n",
        "from statistics import harmonic_mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kcix9SZ05aFF"
      },
      "source": [
        "## Première partie : CRF (Champs aléatoires conditionnels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54iFU6yf5uOe"
      },
      "source": [
        "Préparation des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d_95o7Ik32W"
      },
      "source": [
        "def get_data_for_crf(corpus=\"data/democrat.conll\"):\n",
        "  x, y = [], []\n",
        "  with open(corpus) as democrat:\n",
        "    for line in democrat:\n",
        "          if line.startswith(\"#begin\"): data, sentence = [], []\n",
        "          elif line.startswith(\"#end\"): continue\n",
        "          elif line == \"\\n\":\n",
        "            data.append(sentence)\n",
        "            sentence = []\n",
        "            if len(data) == 5:\n",
        "              item = copy.deepcopy([w for s in data for w in s])\n",
        "              \n",
        "              if len(item) < 150:\n",
        "                for i, w in enumerate(item): w[\"index\"] = str(i)\n",
        "                for j, w1 in enumerate(item[:0:-1]):\n",
        "                  for key in w1.keys():\n",
        "                    if w1[\"y\"] != \"-1\": break\n",
        "                    if key.startswith(\"group\"):\n",
        "                      for w2 in item[-j-2::-1]:\n",
        "                        if w1[\"y\"] != \"-1\": break\n",
        "                        for key1 in w2.keys():\n",
        "                          if key1.startswith(\"group\") and w1[key] == w2[key1]:\n",
        "                            w1[\"y\"] = w2[\"index\"]\n",
        "                            break\n",
        "                item[0][\"y\"] = \"-1\"\n",
        "                y.append([word[\"y\"] for word in item])\n",
        "                for word in item:\n",
        "                  del word[\"y\"]\n",
        "                  for i in range(len(word)-5): del word[\"group\"+str(i)]\n",
        "                x.append(item)\n",
        "                del item           \n",
        "              del data[0]\n",
        "          else:\n",
        "            l = line.split()\n",
        "            if sentence: sentence[-1][\"nextword\"] = l[3]\n",
        "            elif data: data[-1][-1][\"nextword\"] = l[3]\n",
        "            groups = []\n",
        "            for group in l[-1].split(\"|\"):\n",
        "              if group[-1] == \")\": groups.append(group[:-1])\n",
        "            word = {\"prevword\" : sentence[-1][\"word\"] if sentence else data[-1][-1][\"word\"] if data else \"\", \"word\" : l[3], \"pos\" : l[4], \"nextword\" : \"\", \"y\" : \"-1\"}\n",
        "            word.update({\"group\"+str(i) : group  for i, group in enumerate(groups)})\n",
        "            sentence.append(word)\n",
        "  return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UocBBJbv52D3"
      },
      "source": [
        "Construction du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BApHytDjdxan"
      },
      "source": [
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=0.1,\n",
        "    c2=0.1,\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True,\n",
        "    verbose=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNruiradZ_dr"
      },
      "source": [
        "x, y = get_data_for_crf()\n",
        "crf.fit(x[:-100], y[:-100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht8TrYAh55ax"
      },
      "source": [
        "Résultats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT6DWvzAUFvj"
      },
      "source": [
        "def normalize(y):\n",
        "  new_y = []\n",
        "  for t in y:\n",
        "    new_t = []\n",
        "    for i, u in enumerate(t, 1):\n",
        "      if u!=\"-1\":\n",
        "        for k in new_t:\n",
        "          if int(u) in k: k.add(i)\n",
        "          elif i in k: k.add(int(u))\n",
        "        else: new_t.append({int(u), i})\n",
        "    new_y.append(new_t)\n",
        "  return new_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t01T40Lqw2N"
      },
      "source": [
        "def b_cubed(golds, preds):\n",
        "  l_g, l_p = sum(len(gold) for gold in golds), sum(len(pred) for pred in preds)\n",
        "  r = 0.0 if l_g == 0 else sum(len(pred&gold)**2/len(gold) for gold in golds for pred in preds)/l_g\n",
        "  p = 0.0 if l_p == 0 else sum(len(pred&gold)**2/len(pred) for gold in golds for pred in preds)/l_p\n",
        "  f = harmonic_mean((r, p))\n",
        "  return r, p, f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbub5DJSmlsw"
      },
      "source": [
        "def b_cubed_for_batch(golds, preds)\n",
        "  r, p, f = 0, 0, 0\n",
        "  b = [b_cubed(y1, y2) for (y1, y2) in zip(golds, preds)]\n",
        "  for metrics in b:\n",
        "    r += metrics[0]\n",
        "    p += metrics[1]\n",
        "    f += metrics[2]\n",
        "  return r/len(b), p/len(b), f/len(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQWolo79vVSz"
      },
      "source": [
        "def normalize(y):\n",
        "  new_y = []\n",
        "  for t in y:\n",
        "    new_t = []\n",
        "    for i, u in enumerate(t, 1):\n",
        "      if u!=\"-1\":\n",
        "        for k in new_t:\n",
        "          if int(u) in k: k.add(i)\n",
        "          elif i in k: k.add(int(u))\n",
        "        else: new_t.append({int(u), i})\n",
        "    new_y.append(new_t)\n",
        "  return new_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvycmY1tzFF9",
        "outputId": "eebecaba-698f-41a4-a4d2-d621c424c205"
      },
      "source": [
        "r, p, f = b_cubed_for_batch(normalize(y[-100:]), normalize([crf.predict(k) for k in x[-100:]]))\n",
        "print(f\"Rappel : {r}\")\n",
        "print(f\"Précision : {p}\")\n",
        "print(f\"F-micro : {f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rappel : 0.5635911434020358\n",
            "Précision : 0.6727939468088564\n",
            "F-micro : 0.5977205882392462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta6lit4VvTIC"
      },
      "source": [
        "#Conclusion\n",
        "\n",
        "Ce modèle n'est pas du haute qualité. Il vaudrait mieux essayer des algorithmes plus efficaces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9vDGR3r57of"
      },
      "source": [
        "## Deuxième partie : Réseau génératif\n",
        "\n",
        "J'ai décidé de réaliser des expériences avec des réseaux de neurones et de comparer des résultats avec un modèle précédent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG485u8d6Lov"
      },
      "source": [
        "Préparation des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0WKZJzmN0_4"
      },
      "source": [
        "def get_base(corpus=\"data/democrat.conll\"):\n",
        "  x, y, pos = [], [], []\n",
        "  with open(corpus) as democrat:\n",
        "      for line in democrat:\n",
        "          if line.startswith(\"#begin\"):\n",
        "              x_doc, y_doc, x_words, y_words, pos_doc = [], [], [], [], \"\"\n",
        "              continue\n",
        "          elif line.startswith(\"#end\"):\n",
        "              x.append(x_doc)\n",
        "              y.append(y_doc)\n",
        "              pos.append(pos_doc)\n",
        "              continue\n",
        "          l = line.split()\n",
        "          if not(l):\n",
        "              if x_words and y_words:\n",
        "                  x_doc.append(x_words)\n",
        "                  y_doc.append(y_words)\n",
        "                  x_words, y_words = [], []\n",
        "          else:\n",
        "              pos_doc += l[4] + \" \"\n",
        "              x_words.append(l[2:5]+[l[6]])\n",
        "              y_words.append(l[-1])\n",
        "  joblib.dump(x, \"data/x_words\")\n",
        "  joblib.dump(y, \"data/y_words\")\n",
        "  joblib.dump(pos, \"data/pos\")\n",
        "  return x, y, pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSyivGZ2F8XO"
      },
      "source": [
        "def get_vectors(x = \"data/x_words\", y=\"data/y_words\", pos=\"data/pos\", model='data/cc.fr.300.bin', path=True):\n",
        "  if path:\n",
        "    x = joblib.load(x)\n",
        "    y = joblib.load(y)\n",
        "  pos = joblib.load(pos)\n",
        "  tfidf = TidfVectorizer().fit(pos)\n",
        "  ft = fasttext.load_model(model)\n",
        "  new_x = np.asarray([np.array([np.array([np.array([ft.get_word_vector(word[1]), tfidf.transform([word[2]]).toarray()[0]]) for word in sentence]) for sentence in doc]) for doc in x])\n",
        "  new_y = []\n",
        "  indexes = []\n",
        "  for doc in y:\n",
        "      new_doc = []\n",
        "      for sentence in doc:\n",
        "          new_sentence = []\n",
        "          for word in sentence:\n",
        "              new_word = []\n",
        "              if word == \"-\" and not(indexes): new_word.append(np.array(-1))\n",
        "              else:\n",
        "                  words = word.split(\"|\")\n",
        "                  for index in words:\n",
        "                      if index[0] == \"(\":\n",
        "                          indexes.append(int(index[1:]))\n",
        "                      elif index[-1] == \")\":\n",
        "                          indexes.remove(int(index[:-1]))\n",
        "                          new_word.append(int(index[:-1]))\n",
        "                  new_word += indexes\n",
        "              new_sentence.append(np.array(new_word))\n",
        "          new_doc.append(np.array(new_sentence))\n",
        "      new_y.append(np.array(new_doc))\n",
        "  new_y = np.asarray(new_y)\n",
        "  joblib.dump(new_x, \"data/x_vecs\")\n",
        "  joblib.dump(new_y, \"data/y_vecs\")\n",
        "  return new_x, new_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn4GCWQMu5LQ"
      },
      "source": [
        "def transform_data_to_torch(x=\"data/x_vecs\", y=\"data/y_vecs\", path=True):\n",
        "  if path:\n",
        "    x = joblib.load(x)\n",
        "    y = joblib.load(y)\n",
        "  x_trues, y_trues = [], []\n",
        "  for doc, y_doc in zip(x, y):\n",
        "      for i in range(len(doc)-4):\n",
        "          x_trues.append(doc[i:i+5])\n",
        "          answers = []\n",
        "          for s, sentence in enumerate(y_doc[i:i+5], 1):\n",
        "              for w, word in enumerate(sentence, 1):\n",
        "                  if not(np.array_equal(word, [-1])):\n",
        "                      for r in range(len(word)):\n",
        "                          answers.append((s, w, word[r]))\n",
        "          new_answers = []\n",
        "          chains = [z[2] for z in answers]\n",
        "          passed = []\n",
        "          for a, answer in enumerate(answers):\n",
        "              k=0\n",
        "              if answer[2] not in passed:\n",
        "                  while answer[2] == chains[a+k]:\n",
        "                      k+=1\n",
        "                      if a+k>=len(chains): break\n",
        "                  if answer[2] in chains[a+k:]: new_answers+=[i for i in answers if i[2] == answer[2]]\n",
        "                  passed.append(answer[2])\n",
        "          y_true = []\n",
        "          for ind in {z[2] for z in new_answers}:\n",
        "              y_str = \"\"\n",
        "              for new_answer in new_answers:\n",
        "                  if new_answer[2] == ind: y_str+=str(new_answer[0])+\".\"+str(new_answer[1])+\";\"\n",
        "              y_true.append(y_str) \n",
        "          y_trues.append(y_true)\n",
        "  joblib.dump(x_trues, \"data/x_exp\")\n",
        "  joblib.dump(y_trues, \"data/y_exp\")\n",
        "\n",
        "  return x_trues, y_trues"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gP0lo7Q6SKD"
      },
      "source": [
        "Génération des batches de la taille différente (selon la taille de la phrase)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMbBLr2Bn_xj"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, texts, labels, maxlen, out2ind, device):\n",
        "    self.texts = texts\n",
        "    self.labels = labels\n",
        "    self.device = device\n",
        "    self.maxlen = maxlen\n",
        "    self.out2ind = out2ind\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    texts, labels = x_trues[item], y_trues[item]\n",
        "    full = []\n",
        "    for chain in labels:\n",
        "      new_examples = []\n",
        "      for sentence in texts:\n",
        "        for word in sentence:\n",
        "          new_word = np.concatenate(word)\n",
        "          new_examples.append(new_word)\n",
        "      tens = torch.tensor(new_examples).unsqueeze(0).to(self.device)\n",
        "      full.append(tens)\n",
        "    new_y_trues = [(label[label[:-1].rindex(\";\"):][1:-1], label[:label[:-1].rindex(\";\")]) for label in labels]\n",
        "    gold = [(torch.tensor([self.out2ind[l] for l in list(inp)]+[self.out2ind['PAD'] for _ in range(6-len(inp))], dtype=torch.long, device=self.device), \n",
        "             torch.tensor([self.out2ind[l] for l in list(y)]+[self.out2ind['EOS']]+[self.out2ind['PAD'] for _ in range(self.maxlen-len(y))], dtype=torch.long, device=self.device)) for inp, y in new_y_trues]\n",
        "    return full, gold\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2OVZTL-7Uh9"
      },
      "source": [
        "Constrution de la partie Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXzY06jTmZ6n"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, device, hidden_size=300):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True).to(device)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output, hidden = self.gru(input, hidden)\n",
        "        return output, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrmvTGwW7Xnz"
      },
      "source": [
        "Construction de la partie Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgr-Cf3oxKFj"
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, output_size, hidden_size, device):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding =  nn.Embedding(output_size, hidden_size).to(device)\n",
        "        self.start_embedding = nn.Embedding(output_size, 20).to(device)\n",
        "        self.gru = nn.GRU(hidden_size+120, hidden_size).to(device)\n",
        "        self.out = nn.Linear(hidden_size, output_size).to(device)\n",
        "        \n",
        "    def forward(self, prevsym, starting, hidden, *params):\n",
        "        st_input = torch.flatten(self.start_embedding(starting)).view(1,1,120)\n",
        "        input = torch.cat((self.embedding(prevsym), st_input), 2)\n",
        "        output, hidden = self.gru(input, hidden)\n",
        "        output = self.out(output[:,-1])\n",
        "        return output, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seCO7y-j7tfb"
      },
      "source": [
        "Entrainement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0779ODbt2hZ-"
      },
      "source": [
        "def train(data, encoder, decoder, hidden_size, maxlen, iters=1, learning_rate=0.01):\n",
        "        print(\"Training...\")\n",
        "        encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "        decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "        criterion = nn.CrossEntropyLoss(ignore_index=15)\n",
        "        for iter in range(iters):\n",
        "            t = tqdm(range(len(data))) \n",
        "            for idx in t:\n",
        "                if idx < 7000:\n",
        "                  continue\n",
        "                loss = 0\n",
        "                b_sentence, b_gold = data[idx]\n",
        "                for sentence, gold in zip(b_sentence, b_gold): \n",
        "                    enc_hidden = torch.zeros(1, 1, decoder.hidden_size, dtype=torch.float32, device=device)\n",
        "                    sentence = sentence.type(torch.float32)\n",
        "                    enc_outputs, enc_hidden = encoder(sentence, enc_hidden)\n",
        "                    dec_input = torch.tensor([[out2ind['SOS']]], dtype=torch.long, device=device)\n",
        "                    dec_hidden = enc_hidden\n",
        "                    word = []\n",
        "                    for symbol in range(maxlen):\n",
        "                        dec_output, dec_hidden = decoder(dec_input, gold[0], dec_hidden, enc_outputs)\n",
        "                        values, ids = torch.max(dec_output, 1)\n",
        "                        dec_input = ids.view(-1, 1)\n",
        "                        loss += criterion(dec_output, gold[1][symbol].view(-1))\n",
        "                        word.append(ind2out[dec_input.item()])\n",
        "                        if dec_input.item() == out2ind['EOS']:\n",
        "                            break\n",
        "                if idx%1000==0:\n",
        "                  print(f'\\n{idx}, new', \"\".join([ind2out[x.item()] for x in gold[1]]).replace('PAD', ''))\n",
        "                  print(\"\".join(word))\n",
        "                  torch.save(enc, 'models/new_encoder.pt')\n",
        "                  torch.save(dec, 'models/new_decoder.pt')\n",
        "                try:\n",
        "                  loss = loss/len(b_sentence)\n",
        "                except ZeroDivisionError:\n",
        "                  loss = loss\n",
        "                if loss == 0:\n",
        "                  continue\n",
        "                loss.backward()\n",
        "                encoder_optimizer.step()\n",
        "                decoder_optimizer.step()\n",
        "                encoder_optimizer.zero_grad()\n",
        "                decoder_optimizer.zero_grad()\n",
        "\n",
        "                t.set_description(f\"loss: {round(float(loss), 3)}\")\n",
        "                t.refresh()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOjsmSPSre5j"
      },
      "source": [
        "x_base, y_base, pos = get_base()\n",
        "new_x, new_y = get_vectors(x_base, y_base, pos, path=False)\n",
        "x, y = transform_data_to_torch(new_x, new_y, path=False)\n",
        "del x_base, new_x, y_base, new_y, pos\n",
        "out2ind = {str(key):key for key in range(10)}\n",
        "out2ind.update({'.':10, ',':11, ';':12, 'SOS': 13, 'EOS':14, 'PAD':15, '_':16})\n",
        "ind2out = {key:value for value, key in out2ind.items()}\n",
        "ds = Dataset(x_trues, y_trues, maxlen, out2ind, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msF-2-Nq8KT8"
      },
      "source": [
        "Initialization du modèle (regardez l'architecture)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrbptj1c6-We"
      },
      "source": [
        "enc = EncoderRNN(device, 383)\n",
        "dec = DecoderRNN(len(out2ind), 383, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MArbeFSLhxih",
        "outputId": "c19ebdb2-3122-4a3a-fba4-3791c2247ef3"
      },
      "source": [
        "enc.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EncoderRNN(\n",
              "  (gru): GRU(383, 383, batch_first=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew7_tX_Ph0-V",
        "outputId": "2fc0438f-0492-4ea7-8f87-f19b0211c925"
      },
      "source": [
        "dec.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecoderRNN(\n",
              "  (embedding): Embedding(17, 383)\n",
              "  (start_embedding): Embedding(17, 20)\n",
              "  (gru): GRU(503, 383)\n",
              "  (out): Linear(in_features=383, out_features=17, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "662fe86394b24318bf30c8a84360fc4d",
            "7201df939b23476b9e3d966f54f6bf00",
            "e05a20b021cc43ef8d4318f428e8a655",
            "6cb474c2410345a88cdd4570760b8aa7",
            "cb74ab8405704c89ba39df7b628d4582",
            "90e1ee2824314506b4e3158d7a82fdb9",
            "e4b0585972ea4639a68005cef05116cb",
            "1875ceb9f28742ecb88ab06a7880fabf"
          ]
        },
        "id": "zjdZPAjs69MQ",
        "outputId": "78bc84b9-cf19-4fe9-bf39-6c95f9ef4355"
      },
      "source": [
        "train(ds, enc, dec, 383, 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "662fe86394b24318bf30c8a84360fc4d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=25188.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0, new 5.24;5.25EOS\n",
            "5.12;.;EOS\n",
            "\n",
            "1000, new 1.15;4.1;4.9EOS\n",
            "5.25;1.2;1.;4.11;4;..4;1;1.2;1.141;;1;;.522;.1;4;1;;.;4;11;;1;;1;;1;;1;;1;;1;;1;;1;;1;;1;;1;;1;;1;;1\n",
            "\n",
            "2000, new 2.8;2.9;2.10;2.11;2.12;2.13EOS\n",
            "2.12;.11.11;2..;;.12..;.12..12..12.11.11.11..11..11..11..1;..1;..1;..1..11..1..1..1..1..1..1..1..1..\n",
            "\n",
            "3000, new 2.1;2.2;3.5;3.6;5.52;5.53;5.60EOS\n",
            "5.11;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.;1.\n",
            "\n",
            "4000, new 2.2;2.3;2.4;2.11;2.15;4.2;4.3;4.4;4.13;4.19;4.30;5.1;5.22;5.27;5.45EOS\n",
            "5.2EOS\n",
            "\n",
            "5000, new 4.21;4.25;4.35;4.38;4.41;4.46;5.4;5.5;5.18EOS\n",
            "5.3;515;5..;;51152..;.1511;..............................................3.;.155145..3;...1;........\n",
            "\n",
            "6000, new 3.32;3.33EOS\n",
            "3.33;33.1333333..33;3333333333333333333333333;33333333333333333333333333333333333333333333.33;333333\n",
            "\n",
            "7000, new 5.56EOS\n",
            "5.45;55.55.5;55.5;55.113;;..555.555.55455.;555.555.555;5.555.55;55.555.55;55.555.55;55.55;55.55;55.5\n",
            "\n",
            "8000, new 1.130;1.131;1.132;1.133;1.134EOS\n",
            "1.1101.11.1111111;111.11111.111111.1111.111.111.111.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.\n",
            "\n",
            "9000, new 3.4;3.5;3.6EOS\n",
            "1.2;2..;3.;3;3.;3;3.;EOS\n",
            "\n",
            "10000, new 4.4;4.5;4.6EOS\n",
            "1.1;3.2443.EOS\n",
            "\n",
            "11000, new 5.11;5.23EOS\n",
            "5.1;5..;;2EOS\n",
            "\n",
            "12000, new 1.18;1.19;1.20;1.38EOS\n",
            "1.1;..;2113211;...;211;...;211;...21111;2.11111311.;2311.1111111.;2311.1111111.;2311.11111111.;2311.\n",
            "\n",
            "13000, new 5.66;5.67;5.68;5.72EOS\n",
            "1.4;;..1454..;4;;43;.4;;45;4..54;;4..54;;4..54;;4..54;;4..54;;4..54;;4..54;;4..54;;4..54;;4..54;;4..\n",
            "\n",
            "14000, new 2.7;2.8;2.10;5.12;5.13EOS\n",
            "1.1;1.2;;.11.11.3;211.11.;.11.11.3.1..;.11.1EOS\n",
            "\n",
            "15000, new 1.1;1.10;1.16;1.21;4.18;4.19;4.28EOS\n",
            "4.1;;..544;3..;;..211;..4544;;;;;;;;3..;5.4.4;;;;;;;;;;;;;;;;3.;5.44;;;;;;;;;;;;;;;;;;;3.;5.44;;;;;;\n",
            "\n",
            "16000, new 4.11;4.12;4.13;4.14EOS\n",
            "1.1;1.342...;1..;1.342;1..;.142;13;24;4...3;2;11.;.1;EOS\n",
            "\n",
            "17000, new 5.16;5.17;5.18;5.19EOS\n",
            "5.1;5.;..1214;55;.;55.;;..;5;.;;5.;;.EOS\n",
            "\n",
            "18000, new 1.2;1.9;1.11;1.19;1.27;1.31EOS\n",
            "1.1;1.3;1;1.31;31;.31;1.3;1.3;1.3;1.3;1.3;1.3;1.3;1.3;1.3;1.3;1.3;1.3;1.3;1.3;1.3;1.3;1.3;1.3;1.3;1.\n",
            "\n",
            "19000, new 4.3;4.4;4.5;4.6EOS\n",
            "2.4;;;4.;;4;;12..;;;32.2;;1.;;;.4;;322.4;;;;412;33.;;;;;.4;;;;.4;;;;.4;;;;.4;;;;.4;;;;.4;;;;.4;;;.4;\n",
            "\n",
            "20000, new 3.13;4.6;4.7;4.8;4.9;4.10;4.33;4.34;4.35;4.42;5.1EOS\n",
            "1.41;35.1;413;.1;8.1;5.1;841;.13;.1;5.1;8413;.1;8.1;541.;13;.1;5.1;8413;.1;8.1;541.;13;.1;5.1;8413;.\n",
            "\n",
            "21000, new 5.19;5.20EOS\n",
            "5.152;5.;.5;5.152.;;5.;.5;5;.;2.5;.152.;;.5;5;..;2.;5;;5.;2;;52;;.;5;2;;52;;52;;;.;5;2;;52;;52;;5.;2\n",
            "\n",
            "22000, new 1.1;2.2;2.6EOS\n",
            "2.1;1.11.EOS\n",
            "\n",
            "23000, new 3.17;3.18EOS\n",
            "3.13;3.1;3.33.13.3.;3.13.3.;3.13.3.;3.133.;3.133.;3.133.;3.13.3;3.133.;3.13.3;3.133.;3.13.3;3.13.3;3\n",
            "\n",
            "24000, new 3.46EOS\n",
            "3.13;3.;;3..2;;3.;;31.33.;;3.;;313.33;;.;3133..3..3..3..3..3..3..3..3..3..;313.33.;5;13.3..3..3..3..\n",
            "\n",
            "25000, new 1.11EOS\n",
            "1.1;1.1111111;1.11111;1.1111;1.111;1.111;1.1;1.1;1.111;1.1;1.1;1.111;1.1;1.1;1.111;1.1;1.1;1.111;1.1\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjTeTqCNPPBj"
      },
      "source": [
        "#Conclusion\n",
        "Avec chaque époque, le réseau de neuronnes semble de générer des réponses plus proches des souhaitées. Pourtant, c'est très loin d'être acceptable.\n",
        "\n",
        "Visiblement, des algorithmes de classification sont plus appropriés pour ce tâche. Cependant, il n'est pas possible de comparer ce modèle avec le CRF, car des outputs ne sont pas toujours facilement interprétables.\n",
        "\n",
        "Sans doute, il faudrait continuer des expériences, car des réseaux seq2seq apprennent lentement. Faute des ressources et de temps le modèle n'a même pas traité tous le jeu de données pour un fois. Ainsi, il est difficile de faire une conclusion finale, mais selon des chiffres qu'on voit, un CRF marche mieux. "
      ]
    }
  ]
}